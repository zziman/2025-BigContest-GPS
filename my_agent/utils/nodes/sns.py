# -*- coding: utf-8 -*-
"""
SNS ì¶”ì²œ ë…¸ë“œ
"""
from langchain_google_genai import ChatGoogleGenerativeAI
from my_agent.utils.config import GOOGLE_API_KEY, LLM_MODEL, LLM_TEMPERATURE
from my_agent.utils.state import GraphState
from my_agent.utils.prompt_builder import build_base_context, build_signals_context
from my_agent.utils.postprocess import postprocess_response

def build_web_context(state: GraphState, limit: int = 3) -> str:
    snips = state.get("web_snippets") or []
    rows = []
    for s in snips[:limit]:
        title = s.get("title", "")
        src   = s.get("source", "")
        sn    = s.get("snippet", "")
        rows.append(f"- {title} Â· {src}: {sn}")
    return "\n".join(rows) if rows else "N/A"

def append_sources(text: str, state: GraphState, limit: int = 3) -> str:
    snips = state.get("web_snippets") or []
    if not snips:
        return text
    lines = ["\n\n---\nğŸ”— ì°¸ê³  ì¶œì²˜"]
    for s in snips[:limit]:
        title = s.get("title", "(ì œëª© ì—†ìŒ)")
        src   = s.get("source", "")
        url   = s.get("url", "")
        if url:
            lines.append(f"- {title} Â· {src} Â· {url}")
        else:
            lines.append(f"- {title} Â· {src}")
    return text + "\n".join(lines)

PROMPT = """ë‹¹ì‹ ì€ SNS ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ ê°€ë§¹ì  ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ SNS ì±„ë„ ì¶”ì²œ ë° ì½˜í…ì¸  ì „ëµì„ ì‘ì„±í•˜ì„¸ìš”.

[INTERNAL DATA]
{base_context}
{signals_context}

[EXTERNAL (ìµœê·¼ ë¦¬ë·°/ê¸°ì‚¬/ë¸”ë¡œê·¸ ìŠ¤ë‹ˆí« ìš”ì•½)]
{web_context}

[ì£¼ìš” ê³ ê°ì¸µ]
{persona}

[ì¶”ì²œ ì±„ë„]
{channel_hints}

[ì¶œë ¥ í˜•ì‹]
1) ì¶”ì²œ SNS ì±„ë„ (2~3ê°œ, ê° ì±„ë„ë³„ ì´ìœ )
2) íƒ€ê²Ÿë³„ ì½˜í…ì¸  ì•„ì´ë””ì–´ (3~5ê°œ)
3) í™ë³´ ë©”ì‹œì§€ ì˜ˆì‹œ (3ê°œ)

ì£¼ì˜:
- ë‚´ë¶€ ë°ì´í„°ì™€ ì™¸ë¶€ ìŠ¤ë‹ˆí« ì¤‘ ì–´ë–¤ ê·¼ê±°ë¥¼ ì¼ëŠ”ì§€ ë¬¸ì¥ ëì— (ë‚´ë¶€) / (ì™¸ë¶€)ë¡œ í‘œê¸°
- ê³¼ì¥ ì—†ì´ ì‹¤í–‰ ê°€ëŠ¥í•œ ìˆ˜ì¤€ìœ¼ë¡œë§Œ ì‘ì„±
"""

class SNSNode:
    def __init__(self):
        self.llm = ChatGoogleGenerativeAI(
            model=LLM_MODEL,
            google_api_key=GOOGLE_API_KEY,
            temperature=LLM_TEMPERATURE
        ) if GOOGLE_API_KEY else None
        self.prompt_template = PROMPT
    
    def __call__(self, state: GraphState) -> GraphState:
        card = state.get("card_data", {})
        signals = state.get("signals", [])
        persona = state.get("persona", "")
        channel_hints = state.get("channel_hints", [])

        base_ctx = build_base_context(card)
        sig_ctx  = build_signals_context(signals)
        web_ctx  = build_web_context(state)

        prompt = self.prompt_template.format(
            base_context=base_ctx,
            signals_context=sig_ctx,
            web_context=web_ctx,
            persona=persona,
            channel_hints=", ".join(channel_hints) if channel_hints else "ë°ì´í„° ê¸°ë°˜ ì¶”ì²œ"
        )
        
        if self.llm:
            try:
                response = self.llm.invoke(prompt)
                raw = response.content
            except Exception as e:
                raw = f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}"
        else:
            raw = "(ë°ëª¨) SNS ë§ˆì¼€íŒ… ì „ëµ ìƒì„± ì¤‘..."
        
        state["raw_response"] = raw

        final, actions = postprocess_response(
            raw, card, signals, intent=state.get("intent","GENERAL"),
            web_snippets=state.get("web_snippets"), web_meta=state.get("web_meta")
        )
        final = append_sources(final, state)  # ì°¸ê³  ì¶œì²˜ ì¶”ê°€
        state["final_response"] = final
        state["actions"] = actions
        return state
