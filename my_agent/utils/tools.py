# my_agent/utils/tools.py
# -*- coding: utf-8 -*-
"""
ONE-STOP í†µí•© ìœ í‹¸ë¦¬í‹°
- helpers (ì •ê·œí™”/í¬ë§·/ê²€ì¦)
- policies (ì¬ì‹œë„/ê¸ˆì¹™ì–´/ë ˆì´íŠ¸ë¦¬ë°‹)
- relevance rules (ì‘ë‹µ í’ˆì§ˆ ê·œì¹™)
- prompt_builder / postprocess
- data_collector / feature_builder / store_resolver
- memory / relevance check (íŒŒì´í”„ë¼ì¸ìš©)
ë…¸ë“œëŠ” ì´ íŒŒì¼ í•˜ë‚˜ë§Œ ì„í¬íŠ¸í•˜ë©´ ë¨.
"""
from typing import Dict, Any, Tuple, List, Optional, Tuple
import re
import pandas as pd

from my_agent.utils.config import CONFIRM_ON_MULTI, ENABLE_RELEVANCE_CHECK
from my_agent.utils.state import GraphState
from mcp.adapter_client import call_mcp_tool
from langchain_core.messages import HumanMessage, AIMessage

from urllib.parse import urlparse

# =============================================================================
# helpers  (ê¸°ì¡´ helpers.py)
# =============================================================================
def normalize_store_name(name: str) -> str:
    """ê°€ë§¹ì ëª… ì •ê·œí™”: ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ì œê±°"""
    if not name:
        return ""
    return re.sub(r"\s+", "", name).strip()

def safe_float(value: Any, default: float = 0.0) -> float:
    """ì•ˆì „í•œ float ë³€í™˜"""
    try:
        return float(value) if value is not None else default
    except (ValueError, TypeError):
        return default

def safe_int(value: Any, default: int = 0) -> int:
    """ì•ˆì „í•œ int ë³€í™˜"""
    try:
        return int(value) if value is not None else default
    except (ValueError, TypeError):
        return default

def format_percentage(value: float, decimals: int = 0) -> str:
    """í¼ì„¼í…Œì´ì§€ í¬ë§·íŒ…"""
    return f"{value * 100:.{decimals}f}%"

def extract_top_demographics(card: Dict[str, Any]) -> list[tuple[str, float]]:
    """ì„±ë³„/ì—°ë ¹ëŒ€ ë¹„ì¤‘ ìƒìœ„ 3ê°œ ì¶”ì¶œ"""
    demo_keys = [
        ("ë‚¨ì„±_20ëŒ€ì´í•˜", "male_u20"),
        ("ë‚¨ì„±_30ëŒ€", "male_30"),
        ("ë‚¨ì„±_40ëŒ€", "male_40"),
        ("ë‚¨ì„±_50ëŒ€", "male_50"),
        ("ë‚¨ì„±_60ëŒ€ì´ìƒ", "male_60"),
        ("ì—¬ì„±_20ëŒ€ì´í•˜", "female_u20"),
        ("ì—¬ì„±_30ëŒ€", "female_30"),
        ("ì—¬ì„±_40ëŒ€", "female_40"),
        ("ì—¬ì„±_50ëŒ€", "female_50"),
        ("ì—¬ì„±_60ëŒ€ì´ìƒ", "female_60"),
    ]
    demo_map = {}
    for label, key in demo_keys:
        val = card.get(key, 0) or 0
        demo_map[label] = safe_float(val)
    sorted_demo = sorted(demo_map.items(), key=lambda x: x[1], reverse=True)
    return sorted_demo[:3]

def validate_card_data(card: Dict[str, Any]) -> tuple[bool, Optional[str]]:
    """ì¹´ë“œ ë°ì´í„° í•„ìˆ˜ í•„ë“œ ê²€ì¦"""
    required = ["mct_id", "yyyymm", "mct_name"]
    for field in required:
        if field not in card or not card[field]:
            return False, f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}"
    return True, None

# =============================================================================
# policies  (ê¸°ì¡´ policies.py)
# =============================================================================
MAX_RETRIES = 2
TIMEOUT_SECONDS = 30
FORBIDDEN_WORDS = ["ë¹„ì†ì–´ì˜ˆì‹œ1", "ë¹„ì†ì–´ì˜ˆì‹œ2"]

def should_retry(state: Dict[str, Any]) -> bool:
    """ì¬ì‹œë„ ì—¬ë¶€ íŒë‹¨"""
    return state.get("retry_count", 0) < MAX_RETRIES

def check_forbidden_words(text: str) -> tuple[bool, list[str]]:
    """ê¸ˆì¹™ì–´ ê²€ì‚¬"""
    found = [w for w in FORBIDDEN_WORDS if w in (text or "").lower()]
    return len(found) == 0, found

def apply_rate_limit(user_id: str) -> bool:
    """ë ˆì´íŠ¸ë¦¬ë°‹ ì²´í¬ (ë”ë¯¸)"""
    return True

# =============================================================================
# relevance rules  (ê¸°ì¡´ relevance_rules.py)
# =============================================================================
def check_base_relevance(user_query: str, response: str, card: Dict[str, Any]) -> Tuple[bool, str]:
    """ê¸°ë³¸ ê´€ë ¨ì„± ì²´í¬"""
    if len((response or "").strip()) < 50:
        return False, "ì‘ë‹µì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ (ìµœì†Œ 50ì í•„ìš”)"
    mct_name = card.get("mct_name", "")
    if mct_name and len(mct_name) > 3 and mct_name not in response:
        return False, f"ê°€ë§¹ì ëª… '{mct_name}'ì´ ì‘ë‹µì— í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"

    # âœ… ë‚´ë¶€/ì™¸ë¶€ ë°ì´í„° ê·¼ê±° ë‹¨ì–´ë¥¼ ëª¨ë‘ í—ˆìš©
    data_keywords = [
        "ì¬ë°©ë¬¸", "ë°°ë‹¬", "ê³ ê°", "ë¹„ì¤‘", "%", "ë§¤ì¶œ", "ìˆœìœ„", "ì‹ ê·œ", "ë‹¨ê³¨", "ë°©ë¬¸",
        # ì™¸ë¶€ ê·¼ê±° ìŠ¤ë‹ˆí« ê´€ë ¨
        "ë¦¬ë·°", "ë¸”ë¡œê·¸", "ê¸°ì‚¬", "ì¶œì²˜", "url"
    ]
    if not any(kw in response for kw in data_keywords):
        return False, "ë°ì´í„° ê·¼ê±°ê°€ ì‘ë‹µì— í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"

    has_numbers = bool(re.search(r"\d+", response))
    if not has_numbers:
        return False, "êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ê°€ ì‘ë‹µì— í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
    return True, "OK"

def check_intent_specific_relevance(intent: str, response: str) -> Tuple[bool, str]:
    """Intentë³„ ì¶”ê°€ ê²€ì¦"""
    rules = {
        "SNS": {
            # âœ… í”Œë«í¼/ì±„ë„ í˜¸ì¹­ ë³´ê°•
            "keywords": ["sns", "ì¸ìŠ¤íƒ€", "ë¦´ìŠ¤", "í‹±í†¡", "ì±„ë„", "ì½˜í…ì¸ ", "í•´ì‹œíƒœê·¸", "í¬ìŠ¤íŒ…", "ë„¤ì´ë²„", "í”Œë ˆì´ìŠ¤", "ì‡¼ì¸ "],
            "min": 2, "msg": "SNS ë§ˆì¼€íŒ… ê´€ë ¨ í‚¤ì›Œë“œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤"
        },
        "REVISIT": {"keywords": ["ì¬ë°©ë¬¸", "ë‹¨ê³¨", "ë¦¬í…ì…˜", "ì¿ í°", "ë©¤ë²„ì‹­", "ìŠ¤íƒ¬í”„", "í¬ì¸íŠ¸", "ì¶©ì„±ë„"], "min": 2, "msg": "ì¬ë°©ë¬¸ ì „ëµ ê´€ë ¨ í‚¤ì›Œë“œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤"},
        "ISSUE":   {"keywords": ["ë¬¸ì œ", "ì´ìŠˆ", "ê°œì„ ", "ì›ì¸", "í•´ê²°", "ì§„ë‹¨", "ì•½ì ", "ìœ„í—˜"], "min": 2, "msg": "ë¬¸ì œ ì§„ë‹¨ ê´€ë ¨ í‚¤ì›Œë“œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤"},
        "GENERAL": {"keywords": ["ì „ëµ", "ë§ˆì¼€íŒ…", "ë°©ì•ˆ", "ì œì•ˆ", "ì¶”ì²œ"], "min": 1, "msg": "ë§ˆì¼€íŒ… ì „ëµ ê´€ë ¨ í‚¤ì›Œë“œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤"},
    }
    rule = rules.get((intent or "").upper())
    if not rule:
        return True, "OK"
    text = (response or "").lower()
    matched = [kw for kw in rule["keywords"] if kw in text]
    if len(matched) < rule["min"]:
        return False, f"{rule['msg']} (í•„ìš”: {rule['min']}ê°œ, ë°œê²¬: {len(matched)}ê°œ)"
    return True, "OK"

def check_forbidden_content(response: str) -> Tuple[bool, List[str]]:
    """ê¸ˆì§€ ì½˜í…ì¸  ì²´í¬(ì˜¤íƒ ì¤„ì´ê¸°)"""
    # âœ… ë§ˆì¼€íŒ… ë¬¸ë§¥ì—ì„œ ì •ìƒì ìœ¼ë¡œ ì“°ì´ëŠ” 'ì§„ë‹¨/ì²˜ë°©' ì œê±°
    forbidden_patterns = ["100% ë³´ì¥", "ë¬´ì¡°ê±´ ì„±ê³µ", "í™•ì‹¤í•œ íš¨ê³¼", "ì ˆëŒ€", "ë°˜ë“œì‹œ"]
    found = []
    low = (response or "").lower()
    for p in forbidden_patterns:
        if p.lower() in low:
            found.append(p)
    return len(found) == 0, found

# =============================================================================
# prompt builder  (ê¸°ì¡´ prompt_builder.py)
# =============================================================================
def build_base_context(card: Dict[str, Any]) -> str:
    name = card.get("mct_name", "í•´ë‹¹ ê°€ë§¹ì ")
    industry = card.get("industry", "ì—…ì¢… ë¯¸ìƒ")
    district = card.get("district", "")
    yyyymm = card.get("yyyymm", "")
    repeat_rate   = format_percentage(card.get("repeat_rate", 0))
    delivery_share= format_percentage(card.get("delivery_share", 0))
    new_rate      = format_percentage(card.get("new_rate", 0))
    top_demos = extract_top_demographics(card)
    demo_str = ", ".join([f"{label} {format_percentage(val)}" for label, val in top_demos])
    return f"""
[ê°€ë§¹ì  ê¸°ë³¸ ì •ë³´ - {yyyymm}]
- ìƒí˜¸ëª…: {name}
- ì—…ì¢…: {industry}
- ì§€ì—­: {district}
- ì¬ë°©ë¬¸ìœ¨: {repeat_rate}
- ë°°ë‹¬ ë¹„ì¤‘: {delivery_share}
- ì‹ ê·œ ê³ ê° ë¹„ì¤‘: {new_rate}
- ì£¼ìš” ê³ ê°ì¸µ: {demo_str}
- ê±°ì£¼ ê³ ê°: {format_percentage(card.get("residential_share", 0))}
- ìœ ë™ ê³ ê°: {format_percentage(card.get("floating_share", 0))}
""".strip()

def build_signals_context(signals: list[str]) -> str:
    if not signals: return ""
    desc = {
        "RETENTION_ALERT": "âš ï¸ ì¬ë°©ë¬¸ìœ¨ì´ ë‚®ìŒ (20% ë¯¸ë§Œ)",
        "CHANNEL_MIX_ALERT": "âš ï¸ ë°°ë‹¬ ì˜ì¡´ë„ê°€ ë†’ìŒ (50% ì´ìƒ)",
        "NEW_CUSTOMER_FOCUS": "âœ… ì‹ ê·œ ê³ ê° ìœ ì…ì´ í™œë°œí•¨",
    }
    lines = [desc.get(s, s) for s in signals]
    return "\n[ì£¼ìš” ì´ìŠˆ]\n" + "\n".join(lines)

def build_full_prompt(card: Dict[str, Any], user_query: str, signals: list[str], node_specific_instruction: str) -> str:
    base = build_base_context(card)
    sig = build_signals_context(signals)
    return f"""
ë‹¹ì‹ ì€ ì¹œì ˆí•œ ë§ˆì¼€íŒ… ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.

{base}

{sig}

[ì‚¬ìš©ì ì§ˆë¬¸]
{user_query}

[ì¶œë ¥ ì§€ì¹¨]
{node_specific_instruction}

ê²°ê³¼ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ê³ , ê·¼ê±°ëŠ” ìœ„ ë°ì´í„°ë¥¼ í™œìš©í•˜ì„¸ìš”.
""".strip()

# =============================================================================
# data collector  (ê¸°ì¡´ data_collector.py)
# =============================================================================
def load_card_and_region_data(state: GraphState) -> GraphState:
    store_id = state.get("store_id")
    if not store_id:
        state["error"] = "store_idê°€ ì—†ìŠµë‹ˆë‹¤"
        return state
    try:
        card_result = call_mcp_tool("load_store_data", store_id=store_id)
        if not card_result.get("success"):
            state["error"] = card_result.get("error", "ì¹´ë“œ ì¡°íšŒ ì‹¤íŒ¨")
            return state
        state["card_data"] = card_result.get("data")
    except Exception as e:
        state["error"] = f"ì¹´ë“œ ì¡°íšŒ ì‹¤íŒ¨: {e}"
        return state

    district = state["card_data"].get("district", "")
    if district:
        try:
            region_result = call_mcp_tool("resolve_region", district=district)
            if region_result.get("success"):
                admin_code = region_result.get("admin_dong_code")
                area_result = call_mcp_tool("load_area_data", admin_dong_code=admin_code)
                if area_result.get("success"):
                    state["area_data"] = area_result.get("data")
                region_data_result = call_mcp_tool("load_region_data", admin_dong_code=admin_code)
                if region_data_result.get("success"):
                    state["region_data"] = region_data_result.get("data")
        except Exception:
            pass
    return state

# =============================================================================
# feature builder  (ê¸°ì¡´ feature_builder.py)
# =============================================================================
def build_features(state: GraphState) -> GraphState:
    card = state.get("card_data")
    if not card:
        state["error"] = "ì¹´ë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"
        return state
    signals: List[str] = []
    if card.get("repeat_rate", 0) < 0.2: signals.append("RETENTION_ALERT")
    if card.get("delivery_share", 0) >= 0.5: signals.append("CHANNEL_MIX_ALERT")
    if card.get("new_rate", 0) > 0.4: signals.append("NEW_CUSTOMER_FOCUS")
    state["signals"] = signals

    top = extract_top_demographics(card)
    persona_parts = [f"{label} ({format_percentage(val)})" for label, val in top[:2]]
    state["persona"] = ", ".join(persona_parts) if persona_parts else "ë°ì´í„° ë¶€ì¡±"

    hints: List[str] = []
    female_30_40 = (card.get("female_30", 0) + card.get("female_40", 0)) > 0.3
    if female_30_40: hints.extend(["ì¸ìŠ¤íƒ€ê·¸ë¨", "ë„¤ì´ë²„ ë¸”ë¡œê·¸"])
    if card.get("floating_share", 0) > 0.5: hints.append("ë°°ë‹¬ì•± í”„ë¡œëª¨ì…˜")
    state["channel_hints"] = hints
    return state

# =============================================================================
# postprocess  (ê¸°ì¡´ postprocess.py)
# =============================================================================
def _safe_str(x) -> str:
    return "" if x is None else str(x)

def _format_yyyymm(yyyymm: Any) -> Optional[str]:
    s = _safe_str(yyyymm)
    if len(s) >= 6 and s[:4].isdigit() and s[4:6].isdigit():
        return f"{s[:4]}ë…„ {s[4:6]}ì›”"
    return None

def _dedup_sources(snips: List[Dict[str, Any]], limit: int = 3) -> List[Dict[str, Any]]:
    seen = set()
    out = []
    for s in snips or []:
        title = _safe_str(s.get("title", "")).strip()
        url   = _safe_str(s.get("url", "")).strip()
        dom   = urlparse(url).netloc if url else _safe_str(s.get("source", "")).strip()
        key = (title.lower(), dom.lower())
        if key in seen:
            continue
        seen.add(key)
        out.append(s)
        if len(out) >= limit:
            break
    return out

def _build_sources_block(snips: List[Dict[str, Any]], meta: Optional[Dict[str, Any]]) -> str:
    snips = _dedup_sources(snips, limit=3)
    if not snips:
        return ""
    lines = ["\n\n---\nğŸ”— ì°¸ê³  ì¶œì²˜"]
    if meta:
        q = _safe_str(meta.get("query", ""))
        prov = _safe_str(meta.get("provider_used", ""))
        if q or prov:
            lines.append(f"*ê²€ìƒ‰ ì •ë³´: provider={prov or 'auto'}, query=\"{q}\"*")
    for s in snips:
        title = _safe_str(s.get("title", "(ì œëª© ì—†ìŒ)"))
        url   = _safe_str(s.get("url", ""))
        src   = _safe_str(s.get("source", urlparse(url).netloc if url else ""))
        date  = _safe_str(s.get("published_at", ""))
        head  = f"- {title} Â· {src}"
        if date:
            head += f" Â· {date}"
        if url:
            head += f" Â· {url}"
        lines.append(head)
        snip = _safe_str(s.get("snippet", "")).strip()
        if snip:
            snip = re.sub(r"\s+", " ", snip)[:220]
            lines.append(f"  â”” {snip}")
    return "\n".join(lines)

def clean_response(response: str) -> str:
    response = re.sub(r"\n{3,}", "\n\n", response or "")
    response = response.strip()
    response = re.sub(r"#{4,}", "###", response)
    return response

def add_proxy_badge(response: str, is_proxy: bool) -> str:
    if is_proxy:
        return "ğŸ“Š [í”„ë¡ì‹œ ê¸°ë°˜ ì¶”ì •]\nì´ ë¶„ì„ì€ ë™ì¼ ì—…ì¢…/ì§€ì—­ì˜ í‰ê·  ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n" + response
    return response

def add_data_quality_badge(response: str, card: Dict[str, Any]) -> str:
    msg = _format_yyyymm(card.get("yyyymm", ""))
    if msg:
        response += f"\n\nğŸ“… **ê¸°ì¤€ ë°ì´í„°**: {msg}"
    return response

def add_disclaimer(response: str, card: Dict[str, Any]) -> str:
    disclaimer = """
---
ğŸ’¡ **ì•ˆë‚´ì‚¬í•­**
- ë³¸ ë¶„ì„ì€ ì‹ í•œì¹´ë“œ ê±°ë˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ í†µê³„ì  ì¶”ì •ì…ë‹ˆë‹¤.
- ì‹¤ì œ ì‹¤í–‰ ì‹œ ê°€ë§¹ì  ìƒí™©ì— ë§ê²Œ ì¡°ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.
- ë§ˆì¼€íŒ… íš¨ê³¼ëŠ” ì‹¤í–‰ ë°©ë²•ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""
    return response + disclaimer

def generate_action_seed(card: Dict[str, Any], signals: List[str], intent: str) -> List[Dict[str, Any]]:
    def format_percentage(x):
        try:
            return f"{float(x):.1f}%"
        except Exception:
            return _safe_str(x)
    actions: List[Dict[str, Any]] = []
    priority = 1
    if "RETENTION_ALERT" in signals:
        actions.append({
            "priority": priority, "category": "retention",
            "title": "ì¬ë°©ë¬¸ ê³ ê° í™•ë³´ í”„ë¡œê·¸ë¨",
            "description": "ìŠ¤íƒ¬í”„/ì¿ í° í”„ë¡œê·¸ë¨ ë„ì…",
            "why": f"í˜„ì¬ ì¬ë°©ë¬¸ìœ¨ {format_percentage(card.get('repeat_rate', 0))}ë¡œ ì—…ì¢… í‰ê·  ëŒ€ë¹„ ë‚®ìŒ",
            "expected_impact": "ì¬ë°©ë¬¸ìœ¨ 5~10%p í–¥ìƒ", "difficulty": "ì¤‘",
        }); priority += 1
    if "CHANNEL_MIX_ALERT" in signals:
        actions.append({
            "priority": priority, "category": "channel",
            "title": "ë°°ë‹¬ ì˜ì¡´ë„ ê°ì†Œ ì „ëµ",
            "description": "ë§¤ì¥ ë‚´ ì‹ì‚¬ í”„ë¡œëª¨ì…˜ ê°•í™”",
            "why": f"ë°°ë‹¬ ë¹„ì¤‘ {format_percentage(card.get('delivery_share', 0))}ë¡œ ë†’ì•„ ìˆ˜ìµì„± ì €í•˜",
            "expected_impact": "ë§ˆì§„ìœ¨ 3~5%p ê°œì„ ", "difficulty": "ì¤‘",
        }); priority += 1
    if not actions:
        actions.append({
            "priority": 1, "category": "general",
            "title": "ì¢…í•© ë§ˆì¼€íŒ… ì§„ë‹¨",
            "description": "í˜„í™© ë¶„ì„ ë° ë§ì¶¤ ì „ëµ ìˆ˜ë¦½",
            "why": "ì²´ê³„ì ì¸ ë§ˆì¼€íŒ… ì „ëµ í•„ìš”",
            "expected_impact": "ë§¤ì¶œ 5~10% í–¥ìƒ", "difficulty": "ì¤‘",
        })
    return actions[:5]

def postprocess_response(
    raw_response: str,
    card: Dict[str, Any],
    signals: List[str],
    intent: str = "GENERAL",
    web_snippets: Optional[List[Dict[str, Any]]] = None,
    web_meta: Optional[Dict[str, Any]] = None,
) -> Tuple[str, List[Dict[str, Any]]]:
    """
    ìµœì¢… í…ìŠ¤íŠ¸ì™€ ì•¡ì…˜ ì‹œë“œ ìƒì„±.
    - web_snippets/metaê°€ ì£¼ì–´ì§€ë©´ í•˜ë‹¨ì— 'ì°¸ê³  ì¶œì²˜' ìë™ ë¶€ì°©
    - ê¸°ì¡´ í˜¸ì¶œë¶€ì™€ í˜¸í™˜: web_* íŒŒë¼ë¯¸í„° ìƒëµ ê°€ëŠ¥
    """
    text = clean_response(raw_response)
    text = add_proxy_badge(text, card.get("proxy", False))
    text = add_data_quality_badge(text, card)

    # (ì„ íƒ) ì°¸ê³  ì¶œì²˜ ì„¹ì…˜
    if web_snippets:
        text += _build_sources_block(web_snippets, web_meta)

    # ë””ìŠ¤í´ë ˆì´ë¨¸ëŠ” í•­ìƒ ë§ˆì§€ë§‰
    text = add_disclaimer(text, card)

    actions = generate_action_seed(card, signals, intent)
    return text, actions

# =============================================================================
# store resolver  (ê¸°ì¡´ store_resolver.py)
# =============================================================================
def resolve_store(state: GraphState) -> GraphState:
    store_name = (state.get("store_name_input") or "").strip()
    if not store_name:
        state["error"] = "ê°€ë§¹ì ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”"; state["need_clarify"] = True; return state
    try:
        result = call_mcp_tool("search_merchant", merchant_name=store_name)
    except Exception as e:
        state["error"] = f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}"; state["need_clarify"] = True; return state
    if not result.get("found"):
        state["error"] = f"'{store_name}'ì— í•´ë‹¹í•˜ëŠ” ê°€ë§¹ì ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"; state["need_clarify"] = True; return state
    candidates = result.get("merchants", [])
    state["store_candidates"] = candidates
    ranked = _rank_candidates(candidates, store_name)
    if CONFIRM_ON_MULTI and len(ranked) > 1:
        state["need_clarify"] = True
        state["final_response"] = "í›„ë³´ê°€ ì—¬ëŸ¬ ê°œì…ë‹ˆë‹¤. ì§€ì ì„ ì„ íƒí•´ì£¼ì„¸ìš”."
        return state
    best = ranked[0]
    state["store_id"] = str(best.get("ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸") or best.get("ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸", ""))
    state["need_clarify"] = False
    return state

def _rank_candidates(candidates: list, query: str) -> list:
    if not candidates: return []
    df = pd.DataFrame(candidates)
    q = normalize_store_name(query)
    df["_norm_name"] = df["ê°€ë§¹ì ëª…"].apply(normalize_store_name)
    df["_exact"] = (df["_norm_name"] == q).astype(int)
    df["_prefix"] = df["_norm_name"].str.startswith(q).astype(int)
    df["_len"] = df["ê°€ë§¹ì ëª…"].str.len()
    df = df.sort_values(by=["_exact", "_prefix", "_len", "ê°€ë§¹ì ëª…"],
                        ascending=[False, False, True, True])
    return df.to_dict("records")

# =============================================================================
# memory  (ê¸°ì¡´ memory.py)
# =============================================================================
def update_conversation_memory(state: GraphState) -> GraphState:
    user_query = state.get("user_query", "")
    final_response = state.get("final_response", "")
    if user_query:
        state["messages"].append(HumanMessage(content=user_query))
    if final_response:
        state["messages"].append(AIMessage(content=final_response))
    if len(state["messages"]) >= 10:
        state["conversation_summary"] = "ìµœê·¼ ëŒ€í™” ìš”ì•½..."
    return state

# =============================================================================
# relevance check stage  (ê¸°ì¡´ relevance_checker.py)
# =============================================================================
def _check_web_citation_rule(state: "GraphState") -> Tuple[bool, str]:
    """
    ì›¹ ìŠ¤ë‹ˆí«ì´ stateì— ìˆëŠ” ê²½ìš°, ì‘ë‹µì— ìµœì†Œí•œì˜ ì¶œì²˜ íŒíŠ¸ê°€ ë“¤ì–´ê°”ëŠ”ì§€ í™•ì¸.
    - 'ì°¸ê³  ì¶œì²˜' ì„¹ì…˜ ë˜ëŠ” 'http(s)://' í˜¹ì€ ë„ë©”ì¸ í”ì  1ê±´ ì´ìƒ
    - ì†Œí”„íŠ¸ ë£°: ì‹¤íŒ¨í•´ë„ í†µê³¼ì‹œí‚¤ê³  ë©”ì‹œì§€ë§Œ ë‚¨ê¹€
    """
    snips = state.get("web_snippets") or []
    if not snips:
        return True, "no web snippets -> skip"

    raw = (state.get("raw_response") or "") + (state.get("final_response") or "")
    raw_low = raw.lower()

    has_anchor = ("ì°¸ê³  ì¶œì²˜" in raw) or ("http://" in raw_low) or ("https://" in raw_low)
    has_domain = any(d in raw_low for d in [".co.kr", ".com", ".net", ".kr"])
    if has_anchor or has_domain:
        return True, "web citations present"
    return False, "web snippets used but no visible citation hint"

def check_relevance(state: "GraphState") -> "GraphState":
    if not ENABLE_RELEVANCE_CHECK:
        state["relevance_passed"] = True
        return state

    raw = state.get("raw_response", "") or ""
    user_q = state.get("user_query", "") or ""
    card = state.get("card_data", {}) or {}
    intent = state.get("intent", "GENERAL") or "GENERAL"

    passed, msg = check_base_relevance(user_q, raw, card)
    if not passed:
        state["relevance_passed"] = False
        state["error"] = f"[Relevance] {msg}"
        state["retry_count"] = state.get("retry_count", 0) + 1
        return state

    passed, msg = check_intent_specific_relevance(intent, raw)
    if not passed:
        state["relevance_passed"] = False
        state["error"] = f"[Relevance] {msg}"
        state["retry_count"] = state.get("retry_count", 0) + 1
        return state

    # ì†Œí”„íŠ¸ ì›¹ ì¸ìš© ê·œì¹™
    passed, msg = _check_web_citation_rule(state)
    if not passed:
        state["error"] = f"[Relevance][Soft] {msg}"
        # í•˜ë“œ ì‹¤íŒ¨ë¡œ ëŒë¦¬ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ë‘ ì¤„ ì£¼ì„ í•´ì œ
        # state["relevance_passed"] = False
        # return state

    state["relevance_passed"] = True
    return state
