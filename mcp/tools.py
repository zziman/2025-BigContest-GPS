# mcp/tools.py (ìµœì¢… ì •ë¦¬ ë²„ì „)
# -*- coding: utf-8 -*-
"""
MCP íˆ´ í•¨ìˆ˜ (DuckDB ê¸°ë°˜)

ê³µí†µ ë§¤í•‘ ì»¬ëŸ¼: ê¸°ì¤€ë…„ì›”, ì—…ì¢…, ìƒê¶Œ_ì§€ë¦¬

í•¨ìˆ˜:
- search_merchant(merchant_name): ê°€ë§¹ì ëª…/ID ê²€ìƒ‰
- load_store_data(store_id, latest_only): ê°€ë§¹ì  ë°ì´í„° ì¡°íšŒ
- load_bizarea_data(store_row, all_matches): ìƒê¶Œ ë°ì´í„° ì¡°íšŒ
"""

from __future__ import annotations
import re
from pathlib import Path
from typing import Dict, Any, Optional, List, Union

import pandas as pd
import duckdb

from my_agent.utils.config import (
    FRANCHISE_CSV, BIZ_AREA_CSV,
    DUCKDB_PATH, USE_DUCKDB
)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DuckDB ì—°ê²° (ì‹±ê¸€í„´)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
_DB_CONNECTION: Optional[duckdb.DuckDBPyConnection] = None


def _get_db_connection():
    """DuckDB ì—°ê²° íšë“ (ì¬ì‚¬ìš©)"""
    global _DB_CONNECTION
    if _DB_CONNECTION is None:
        db_path = Path(DUCKDB_PATH).expanduser()
        if not db_path.exists():
            raise FileNotFoundError(
                f"âŒ DuckDB íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {db_path}\n"
                f"ğŸ’¡ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”: python scripts/build_duckdb.py"
            )
        _DB_CONNECTION = duckdb.connect(str(db_path), read_only=True)
    return _DB_CONNECTION


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CSV ê¸°ë°˜ ë¡œë”© (ë ˆê±°ì‹œ - USE_DUCKDB=Falseì¼ ë•Œë§Œ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
_FRANCHISE_DF: Optional[pd.DataFrame] = None
_BIZAREA_DF: Optional[pd.DataFrame] = None


def _file_exists(path: str) -> bool:
    return Path(path).exists() and Path(path).is_file()


def _load_franchise_df() -> pd.DataFrame:
    """ê°€ë§¹ì  CSV ë¡œë“œ (ì‹±ê¸€í„´ ìºì‹œ)"""
    global _FRANCHISE_DF
    if _FRANCHISE_DF is None:
        if not _file_exists(FRANCHISE_CSV):
            raise FileNotFoundError(f"franchise CSV not found: {FRANCHISE_CSV}")
        df = pd.read_csv(FRANCHISE_CSV)
        for col in ["ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸", "ê°€ë§¹ì ëª…", "ê¸°ì¤€ë…„ì›”", "ì—…ì¢…", "ìƒê¶Œ_ì§€ë¦¬"]:
            if col in df.columns:
                df[col] = df[col].astype(str)
        _FRANCHISE_DF = df
    return _FRANCHISE_DF


def _load_bizarea_df() -> pd.DataFrame:
    """ìƒê¶Œ CSV ë¡œë“œ (ì‹±ê¸€í„´ ìºì‹œ)"""
    global _BIZAREA_DF
    if _BIZAREA_DF is None:
        if not _file_exists(BIZ_AREA_CSV):
            raise FileNotFoundError(f"biz area CSV not found: {BIZ_AREA_CSV}")
        df = pd.read_csv(BIZ_AREA_CSV)
        for col in ["ê¸°ì¤€ë…„ì›”", "ìƒê¶Œ_ì§€ë¦¬", "ì—…ì¢…"]:
            if col in df.columns:
                df[col] = df[col].astype(str)
        _BIZAREA_DF = df
    return _BIZAREA_DF


def _to_serializable_row(row: Union[pd.Series, Dict[str, Any]]) -> Dict[str, Any]:
    """pandas Series/Dict â†’ JSON ì§ë ¬í™”"""
    if isinstance(row, dict):
        return {k: (None if pd.isna(v) else v) for k, v in row.items()}
    return {k: (None if pd.isna(v) else v) for k, v in row.to_dict().items()}


def _to_serializable_records(df: pd.DataFrame) -> List[Dict[str, Any]]:
    """DataFrame â†’ List[dict] ì§ë ¬í™”"""
    if df.empty:
        return []
    df2 = df.where(pd.notna(df), None)
    return df2.to_dict(orient="records")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ê°€ë§¹ì  ê²€ìƒ‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def search_merchant(merchant_name: str) -> Dict[str, Any]:
    """
    ê°€ë§¹ì ëª… ë˜ëŠ” ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸ë¡œ ê²€ìƒ‰
    
    Args:
        merchant_name: ê°€ë§¹ì ëª… ë˜ëŠ” ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸
    
    Returns:
        {
            "found": bool,
            "message": str,
            "count": int,
            "merchants": List[dict],
            "search_type": "id" | "name" | None
        }
    """
    q = (merchant_name or "").strip()
    
    if not q:
        return {
            "found": False,
            "message": "ê²€ìƒ‰ì–´ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.",
            "count": 0,
            "merchants": [],
            "search_type": None
        }
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # DuckDB ì‚¬ìš©
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if USE_DUCKDB:
        con = _get_db_connection()
        
        # 1) ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸ íŒ¨í„´ ê°ì§€ (10-11ìë¦¬ ì˜ìˆ«ì)
        store_id_pattern = r'^[A-Z0-9]{10,11}$'
        
        if re.match(store_id_pattern, q.upper()):
            result = con.execute("""
                SELECT DISTINCT 
                    ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸, ê°€ë§¹ì ëª…, ê°€ë§¹ì _ì£¼ì†Œ, ì—…ì¢…, ìƒê¶Œ_ì§€ë¦¬
                FROM franchise
                WHERE ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸ = ?
                ORDER BY ê¸°ì¤€ë…„ì›” DESC
                LIMIT 1
            """, [q.upper()]).fetchdf()
            
            if not result.empty:
                merchants = result.to_dict(orient="records")
                return {
                    "found": True,
                    "message": f"ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸ '{q}' ì¡°íšŒ ì„±ê³µ",
                    "count": 1,
                    "merchants": merchants,
                    "search_type": "id"
                }
            else:
                return {
                    "found": False,
                    "message": f"ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸ '{q}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "count": 0,
                    "merchants": [],
                    "search_type": "id"
                }
        
        # 2) ê°€ë§¹ì ëª… ë¶€ë¶„ ê²€ìƒ‰ (ìµœì‹  ë°ì´í„°ë§Œ, ì¤‘ë³µ ì œê±°)
        result = con.execute("""
            SELECT DISTINCT 
                ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸, ê°€ë§¹ì ëª…, ê°€ë§¹ì _ì£¼ì†Œ, ì—…ì¢…, ìƒê¶Œ_ì§€ë¦¬
            FROM (
                SELECT *, 
                       ROW_NUMBER() OVER (PARTITION BY ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸ ORDER BY ê¸°ì¤€ë…„ì›” DESC) as rn
                FROM franchise
                WHERE ê°€ë§¹ì ëª… LIKE ?
            ) sub
            WHERE rn = 1
            ORDER BY ê°€ë§¹ì ëª…
            LIMIT 50
        """, [f"%{q}%"]).fetchdf()
        
        if result.empty:
            return {
                "found": False,
                "message": f"'{q}'ì™€ ì¼ì¹˜í•˜ëŠ” ê°€ë§¹ì ì´ ì—†ìŠµë‹ˆë‹¤.",
                "count": 0,
                "merchants": [],
                "search_type": "name"
            }
        
        merchants = result.to_dict(orient="records")
        return {
            "found": True,
            "message": f"'{q}' ê²€ìƒ‰ ê²°ê³¼ {len(merchants)}ê°œ",
            "count": len(merchants),
            "merchants": merchants,
            "search_type": "name"
        }
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # CSV ì‚¬ìš© (ë ˆê±°ì‹œ)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    else:
        df = _load_franchise_df()
        store_id_pattern = r'^[A-Z0-9]{10,11}$'
        
        # ID ê²€ìƒ‰
        if re.match(store_id_pattern, q.upper()):
            result = df[df["ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸"] == q.upper()].copy()
            
            if not result.empty:
                result = result.sort_values("ê¸°ì¤€ë…„ì›”", ascending=False)
                result = result.drop_duplicates(subset=["ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸"], keep="first")
                merchants = result[["ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸", "ê°€ë§¹ì ëª…", "ê°€ë§¹ì _ì£¼ì†Œ", "ì—…ì¢…", "ìƒê¶Œ_ì§€ë¦¬"]].to_dict(orient="records")
                
                return {
                    "found": True,
                    "message": f"ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸ '{q}' ì¡°íšŒ ì„±ê³µ",
                    "count": 1,
                    "merchants": merchants,
                    "search_type": "id"
                }
        
        # ê°€ë§¹ì ëª… ê²€ìƒ‰
        mask = df["ê°€ë§¹ì ëª…"].str.contains(q, case=False, na=False)
        result = df[mask].copy()
        
        if result.empty:
            return {
                "found": False,
                "message": f"'{q}'ì™€ ì¼ì¹˜í•˜ëŠ” ê°€ë§¹ì ì´ ì—†ìŠµë‹ˆë‹¤.",
                "count": 0,
                "merchants": [],
                "search_type": "name"
            }
        
        result = result.sort_values("ê¸°ì¤€ë…„ì›”", ascending=False)
        result = result.drop_duplicates(subset=["ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸"], keep="first")
        merchants = result.head(50)[["ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸", "ê°€ë§¹ì ëª…", "ê°€ë§¹ì _ì£¼ì†Œ", "ì—…ì¢…", "ìƒê¶Œ_ì§€ë¦¬"]].to_dict(orient="records")
        
        return {
            "found": True,
            "message": f"'{q}' ê²€ìƒ‰ ê²°ê³¼ {len(merchants)}ê°œ",
            "count": len(merchants),
            "merchants": merchants,
            "search_type": "name"
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ê°€ë§¹ì  ë°ì´í„° ì¡°íšŒ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def load_store_data(store_id: str, latest_only: bool = True) -> Dict[str, Any]:
    """
    store_id ê¸°ì¤€ìœ¼ë¡œ ê°€ë§¹ì  ë°ì´í„° ì¡°íšŒ
    
    Args:
        store_id: ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸
        latest_only: True â†’ ìµœì‹  1ê±´(dict), False â†’ ì „ì²´ ì´ë ¥(list[dict])
    
    Returns:
        {"success": bool, "data": dict or list, "error": str or None}
    """
    sid = str(store_id)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # DuckDB ì‚¬ìš©
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if USE_DUCKDB:
        con = _get_db_connection()
        
        if latest_only:
            query = """
            SELECT * FROM franchise
            WHERE ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸ = ?
            ORDER BY ê¸°ì¤€ë…„ì›” DESC
            LIMIT 1
            """
            result = con.execute(query, [sid]).fetchdf()
            
            if result.empty:
                return {"success": False, "data": None, "error": f"ê°€ë§¹ì  {sid} ì—†ìŒ"}
            
            return {
                "success": True,
                "data": result.iloc[0].to_dict(),
                "error": None
            }
        else:
            query = """
            SELECT * FROM franchise
            WHERE ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸ = ?
            ORDER BY ê¸°ì¤€ë…„ì›” ASC
            """
            result = con.execute(query, [sid]).fetchdf()
            
            if result.empty:
                return {"success": False, "data": None, "error": f"ê°€ë§¹ì  {sid} ì—†ìŒ"}
            
            return {
                "success": True,
                "data": result.to_dict("records"),
                "error": None
            }
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # CSV ì‚¬ìš© (ë ˆê±°ì‹œ)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    else:
        df = _load_franchise_df()
        
        if "ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸" not in df.columns:
            return {"success": False, "data": None, "error": "ì»¬ëŸ¼ 'ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸' ì—†ìŒ"}
        
        store_df = df[df["ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸"] == sid].copy()
        if store_df.empty:
            return {"success": False, "data": None, "error": f"store_id {sid} not found"}
        
        if "ê¸°ì¤€ë…„ì›”" in store_df.columns:
            store_df = store_df.sort_values("ê¸°ì¤€ë…„ì›”")
        
        if latest_only:
            return {
                "success": True,
                "data": _to_serializable_row(store_df.iloc[-1]),
                "error": None
            }
        else:
            return {
                "success": True,
                "data": _to_serializable_records(store_df),
                "error": None
            }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ìƒê¶Œ ë°ì´í„° ì¡°íšŒ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def load_bizarea_data(store_row: Dict[str, Any], all_matches: bool = False) -> Dict[str, Any]:
    """ìƒê¶Œ ë°ì´í„° ì¡°íšŒ
    - DuckDB: ì¡°ê±´ ì¼ì¹˜ í–‰ ì „ë¶€(or 1ê±´) ë°˜í™˜. (ìƒê¶Œ_ì½”ë“œ ì»¬ëŸ¼ ì˜ì¡´ ì œê±°)
    - CSV  : ì •í™• ë§¤ì¹­ ì‹¤íŒ¨ í™•ë¥  0 â†’ í•­ìƒ ë‹¨ê±´ ë°˜í™˜ (all_matches ë¬´ì‹œ)
    """
    required = ["ê¸°ì¤€ë…„ì›”", "ì—…ì¢…", "ìƒê¶Œ_ì§€ë¦¬"]
    missing = [k for k in required if k not in store_row or not store_row.get(k)]
    if missing:
        return {"success": False, "data": None, "error": f"í•„ìˆ˜ í‚¤ ëˆ„ë½: {', '.join(missing)}"}

    yyyymm = str(store_row["ê¸°ì¤€ë…„ì›”"])
    area_geo = str(store_row["ìƒê¶Œ_ì§€ë¦¬"])
    industry = str(store_row["ì—…ì¢…"])

    if USE_DUCKDB:
        con = _get_db_connection()
        if all_matches:
            # ì „ì²´ ë§¤ì¹­ í–‰ ë°˜í™˜ (ì •ë ¬/ìƒê¶Œ_ì½”ë“œ ì˜ì¡´ ì œê±°)
            query = """
            SELECT *
            FROM biz_area
            WHERE ê¸°ì¤€ë…„ì›” = ? AND ìƒê¶Œ_ì§€ë¦¬ = ? AND ì—…ì¢… = ?
            """
            params = [yyyymm, area_geo, industry]
            df = con.execute(query, params).fetchdf()
            if df.empty:
                return {"success": False, "data": None, "error": "ìƒê¶Œ ë°ì´í„° ì—†ìŒ"}
            return {"success": True, "data": df.to_dict("records"), "error": None}
        else:
            # ë‹¨ê±´ë§Œ í•„ìš” â†’ LIMIT 1 (ì¤‘ë³µ ì œê±°/ì •ë ¬ ë¶ˆí•„ìš”)
            query = """
            SELECT *
            FROM biz_area
            WHERE ê¸°ì¤€ë…„ì›” = ? AND ìƒê¶Œ_ì§€ë¦¬ = ? AND ì—…ì¢… = ?
            LIMIT 1
            """
            params = [yyyymm, area_geo, industry]
            df = con.execute(query, params).fetchdf()
            if df.empty:
                return {"success": False, "data": None, "error": "ìƒê¶Œ ë°ì´í„° ì—†ìŒ"}
            return {"success": True, "data": df.iloc[0].to_dict(), "error": None}

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # CSV ë¶„ê¸°: ì •í™• ë§¤ì¹­ ì‹¤íŒ¨ í™•ë¥  0 â†’ í•­ìƒ ë‹¨ê±´ ë°˜í™˜
    # all_matches ì¸ìëŠ” ë¬´ì‹œ(í•˜ìœ„í˜¸í™˜ ìœ„í•´ ìœ ì§€)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    df_biz = _load_bizarea_df()
    hit = df_biz[
        (df_biz["ê¸°ì¤€ë…„ì›”"] == yyyymm) &
        (df_biz["ìƒê¶Œ_ì§€ë¦¬"] == area_geo) &
        (df_biz["ì—…ì¢…"] == industry)
    ].copy()

    if hit.empty:
        return {"success": False, "data": None, "error": "bizarea not found"}

    # ì •ë ¬ ë¶ˆí•„ìš”, ìƒê¶Œ_ì½”ë“œë„ ì—†ìŒ â†’ ì²« í–‰ë§Œ ì§ ë°˜í™˜
    return {"success": True, "data": _to_serializable_row(hit.iloc[0]), "error": None}
