# mcp/tools.py 
# -*- coding: utf-8 -*-
"""
MCP íˆ´ í•¨ìˆ˜ (DuckDB ê¸°ë°˜)

ê³µí†µ ë§¤í•‘ ì»¬ëŸ¼: ê¸°ì¤€ë…„ì›”, ì—…ì¢…, ìƒê¶Œ_ì§€ë¦¬

í•¨ìˆ˜:
- search_merchant(merchant_name): ê°€ë§¹ì ëª…/ID ê²€ìƒ‰
- load_store_data(store_id, latest_only): ê°€ë§¹ì  ë°ì´í„° ì¡°íšŒ
- load_bizarea_data(store_row, all_matches): ìƒê¶Œ ë°ì´í„° ì¡°íšŒ
"""

from __future__ import annotations
import re
from pathlib import Path
from typing import Dict, Any, Optional, List, Union

import pandas as pd
import duckdb

from my_agent.utils.config import (
    FRANCHISE_CSV, BIZ_AREA_CSV,
    DUCKDB_PATH, USE_DUCKDB
)

# DuckDB ì—°ê²° (ì‹±ê¸€í„´)
_DB_CONNECTION: Optional[duckdb.DuckDBPyConnection] = None


def _get_db_connection():
    """DuckDB ì—°ê²° íšë“"""
    global _DB_CONNECTION
    if _DB_CONNECTION is None:
        db_path = Path(DUCKDB_PATH).expanduser()
        if not db_path.exists():
            raise FileNotFoundError(
                f"âŒ DuckDB íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {db_path}\n"
                f"ğŸ’¡ data.duckdbë¥¼ ë‹¤ìš´ë°›ì•„ data í´ë”ì— ë„£ìœ¼ì„¸ìš”."
            )
        _DB_CONNECTION = duckdb.connect(str(db_path), read_only=True)
    return _DB_CONNECTION


# CSV ê¸°ë°˜ ë¡œë”© (ë ˆê±°ì‹œ - USE_DUCKDB=Falseì¼ ë•Œë§Œ)
_FRANCHISE_DF: Optional[pd.DataFrame] = None
_BIZAREA_DF: Optional[pd.DataFrame] = None


def _file_exists(path: str) -> bool:
    return Path(path).exists() and Path(path).is_file()


def _load_franchise_df() -> pd.DataFrame:
    """ê°€ë§¹ì  CSV ë¡œë“œ (ì‹±ê¸€í„´ ìºì‹œ)"""
    global _FRANCHISE_DF
    if _FRANCHISE_DF is None:
        if not _file_exists(FRANCHISE_CSV):
            raise FileNotFoundError(f"franchise CSV not found: {FRANCHISE_CSV}")
        df = pd.read_csv(FRANCHISE_CSV)
        for col in ["ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸", "ê°€ë§¹ì ëª…", "ê¸°ì¤€ë…„ì›”", "ì—…ì¢…", "ìƒê¶Œ_ì§€ë¦¬"]:
            if col in df.columns:
                df[col] = df[col].astype(str)
        _FRANCHISE_DF = df
    return _FRANCHISE_DF


def _load_bizarea_df() -> pd.DataFrame:
    """ìƒê¶Œ CSV ë¡œë“œ (ì‹±ê¸€í„´ ìºì‹œ)"""
    global _BIZAREA_DF
    if _BIZAREA_DF is None:
        if not _file_exists(BIZ_AREA_CSV):
            raise FileNotFoundError(f"biz area CSV not found: {BIZ_AREA_CSV}")
        df = pd.read_csv(BIZ_AREA_CSV)
        for col in ["ê¸°ì¤€ë…„ì›”", "ìƒê¶Œ_ì§€ë¦¬", "ì—…ì¢…"]:
            if col in df.columns:
                df[col] = df[col].astype(str)
        _BIZAREA_DF = df
    return _BIZAREA_DF


def _to_serializable_row(row: Union[pd.Series, Dict[str, Any]]) -> Dict[str, Any]:
    """pandas Series/Dict â†’ JSON ì§ë ¬í™”"""
    if isinstance(row, dict):
        return {k: (None if pd.isna(v) else v) for k, v in row.items()}
    return {k: (None if pd.isna(v) else v) for k, v in row.to_dict().items()}


def _to_serializable_records(df: pd.DataFrame) -> List[Dict[str, Any]]:
    """DataFrame â†’ List[dict] ì§ë ¬í™”"""
    if df.empty:
        return []
    df2 = df.where(pd.notna(df), None)
    return df2.to_dict(orient="records")


# ê°€ë§¹ì  ê²€ìƒ‰
def search_merchant(merchant_name: str) -> Dict[str, Any]:
    """
    ê°€ë§¹ì ëª…(ë§ˆìŠ¤í‚¹ í¬í•¨) ë˜ëŠ” ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸ë¡œ ê²€ìƒ‰

    ìš°ì„ ìˆœìœ„
    1. ë³„ê°œìˆ˜ ì •í™•íˆ ì¼ì¹˜ (ì •í™•ë§¤ì¹­)
    2. ë³„ê°œìˆ˜ ë‹¬ë¼ë„ prefix ë™ì¼ (í™•ì¥ë§¤ì¹­)
    3. ì¼ë°˜ LIKE ê²€ìƒ‰
    """
    import re
    import pandas as pd
    import numpy as np

    def _to_py(obj):
        """numpy â†’ Python ê¸°ë³¸í˜• ë³€í™˜"""
        if isinstance(obj, (np.generic,)):
            return obj.item()
        return obj

    q = (merchant_name or "").strip()
    if not q:
        return {
            "found": False,
            "message": "ê²€ìƒ‰ì–´ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.",
            "count": 0,
            "merchants": [],
            "search_type": None,
        }

    store_id_pattern = r"^[A-Z0-9]{10,11}$"

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ§­ DuckDB ì‚¬ìš©
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if USE_DUCKDB:
        con = _get_db_connection()

        # A) ê°€ë§¹ì ID ì§ì ‘ ì¡°íšŒ
        if re.match(store_id_pattern, q.upper()):
            df = con.execute(
                """
                SELECT DISTINCT
                    ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸, ê°€ë§¹ì ëª…, ê°€ë§¹ì _ì£¼ì†Œ, ì—…ì¢…, ìƒê¶Œ_ì§€ë¦¬
                FROM franchise
                WHERE ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸ = ?
                ORDER BY ê¸°ì¤€ë…„ì›” DESC
                LIMIT 1
                """,
                [q.upper()],
            ).fetchdf()

            if df.empty:
                return {
                    "found": False,
                    "message": f"ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸ '{q}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "count": 0,
                    "merchants": [],
                    "search_type": "id",
                }

            merchants = [
                {k: _to_py(v) for k, v in row.items()} for row in df.to_dict("records")
            ]
            return {
                "found": True,
                "message": f"ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸ '{q}' ì¡°íšŒ ì„±ê³µ",
                "count": 1,
                "merchants": merchants,
                "search_type": "id",
            }

        # B) ë§ˆìŠ¤í‚¹ ë§¤ì¹­ (ì •í™• â†’ í™•ì¥)
        if "*" in q:
            m = re.match(r"^([^\*]*)(\*+)$", q)
            if m:
                prefix_raw = m.group(1)
                star_count = len(m.group(2))
                mask_len = len(prefix_raw) + star_count

                sql_base = r"""
                WITH base AS (
                  SELECT
                    ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸, ê°€ë§¹ì ëª…, ê°€ë§¹ì _ì£¼ì†Œ, ì—…ì¢…, ìƒê¶Œ_ì§€ë¦¬, ê¸°ì¤€ë…„ì›”,
                    REGEXP_REPLACE(
                      REGEXP_REPLACE(
                        REGEXP_REPLACE(ê°€ë§¹ì ëª…, '\s+', ''),
                        '[()\{\}\[\]<>Â·â€¢\-\_\/]', ''
                      ),
                      'ì $', ''
                    ) AS norm_name
                  FROM franchise
                ),
                dedup AS (
                  SELECT *, ROW_NUMBER() OVER (
                    PARTITION BY ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸ ORDER BY ê¸°ì¤€ë…„ì›” DESC
                  ) rn
                  FROM base
                )
                SELECT DISTINCT
                  ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸, ê°€ë§¹ì ëª…, ê°€ë§¹ì _ì£¼ì†Œ, ì—…ì¢…, ìƒê¶Œ_ì§€ë¦¬, norm_name
                FROM dedup
                WHERE rn = 1
                """

                # 1ï¸âƒ£ ë³„ê°œìˆ˜ ì •í™•íˆ ì¼ì¹˜
                sql_exact = sql_base + """
                  AND LENGTH(norm_name) = ?
                  AND norm_name LIKE ?
                  ORDER BY ê°€ë§¹ì ëª…
                """
                df_exact = con.execute(
                    sql_exact, [mask_len, f"{prefix_raw}%"]
                ).fetchdf()

                # 2ï¸âƒ£ ë³„ê°œìˆ˜ ë‹¬ë¼ë„ prefix ë™ì¼
                sql_relaxed = sql_base + """
                  AND norm_name LIKE ?
                  ORDER BY LENGTH(norm_name) ASC, ê°€ë§¹ì ëª…
                """
                df_relaxed = con.execute(
                    sql_relaxed, [f"{prefix_raw}%"]
                ).fetchdf()

                if not df_exact.empty:
                    df_final = df_exact
                    priority = "ì •í™•ë§¤ì¹­"
                elif not df_relaxed.empty:
                    df_final = df_relaxed
                    priority = "í™•ì¥ë§¤ì¹­"
                else:
                    return {
                        "found": False,
                        "message": f"ë§ˆìŠ¤í‚¹ '{q}'ë¡œ ì¼ì¹˜/ìœ ì‚¬í•œ ê°€ë§¹ì ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                        "count": 0,
                        "merchants": [],
                        "search_type": "name",
                    }

                merchants = [
                    {k: _to_py(v) for k, v in row.items()}
                    for row in df_final[
                        ["ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸", "ê°€ë§¹ì ëª…", "ê°€ë§¹ì _ì£¼ì†Œ", "ì—…ì¢…", "ìƒê¶Œ_ì§€ë¦¬"]
                    ]
                    .drop_duplicates(subset=["ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸"])
                    .to_dict("records")
                ]

                print(
                    f"[DEBUG] {priority}: {len(merchants)}ê±´ / prefix='{prefix_raw}', len={mask_len}"
                )
                return {
                    "found": True,
                    "message": f"ë§ˆìŠ¤í‚¹ '{q}' {priority} {len(merchants)}ê°œ",
                    "count": len(merchants),
                    "merchants": merchants,
                    "search_type": "name",
                }

        # C) ì¼ë°˜ ë¶€ë¶„ê²€ìƒ‰ (LIKE '%q%')
        df = con.execute(
            """
            SELECT DISTINCT
                ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸, ê°€ë§¹ì ëª…, ê°€ë§¹ì _ì£¼ì†Œ, ì—…ì¢…, ìƒê¶Œ_ì§€ë¦¬
            FROM (
                SELECT *,
                       ROW_NUMBER() OVER (
                         PARTITION BY ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸ ORDER BY ê¸°ì¤€ë…„ì›” DESC
                       ) rn
                FROM franchise
                WHERE ê°€ë§¹ì ëª… LIKE ?
            ) sub
            WHERE rn = 1
            ORDER BY ê°€ë§¹ì ëª…
            LIMIT 50
            """,
            [f"%{q}%"],
        ).fetchdf()

        if df.empty:
            return {
                "found": False,
                "message": f"'{q}'ì™€ ì¼ì¹˜í•˜ëŠ” ê°€ë§¹ì ì´ ì—†ìŠµë‹ˆë‹¤.",
                "count": 0,
                "merchants": [],
                "search_type": "name",
            }

        merchants = [
            {k: _to_py(v) for k, v in row.items()} for row in df.to_dict("records")
        ]
        return {
            "found": True,
            "message": f"'{q}' ê²€ìƒ‰ ê²°ê³¼ {len(merchants)}ê°œ",
            "count": len(merchants),
            "merchants": merchants,
            "search_type": "name",
        }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ§¾ CSV ê²½ë¡œ (ë ˆê±°ì‹œ)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    df = _load_franchise_df().copy()

    if re.match(store_id_pattern, q.upper()):
        hit = df[df["ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸"] == q.upper()].copy()
        if hit.empty:
            return {
                "found": False,
                "message": f"ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸ '{q}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "count": 0,
                "merchants": [],
                "search_type": "id",
            }

        hit = (
            hit.sort_values("ê¸°ì¤€ë…„ì›”", ascending=False)
            .drop_duplicates(subset=["ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸"], keep="first")
        )
        merchants = [
            {k: _to_py(v) for k, v in row.items()}
            for row in hit[
                ["ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸", "ê°€ë§¹ì ëª…", "ê°€ë§¹ì _ì£¼ì†Œ", "ì—…ì¢…", "ìƒê¶Œ_ì§€ë¦¬"]
            ].to_dict("records")
        ]
        return {
            "found": True,
            "message": f"ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸ '{q}' ì¡°íšŒ ì„±ê³µ",
            "count": 1,
            "merchants": merchants,
            "search_type": "id",
        }

    # ë§ˆìŠ¤í‚¹ (CSV ëª¨ë“œ)
    if "*" in q:
        m = re.match(r"^([^\*]*)(\*+)$", q)
        if m:
            prefix_raw = m.group(1)
            star_count = len(m.group(2))
            mask_len = len(prefix_raw) + star_count

            df["norm_name"] = (
                df["ê°€ë§¹ì ëª…"]
                .astype(str)
                .str.replace(r"\s+", "", regex=True)
                .str.replace(r"[()\{\}\[\]<>Â·â€¢\-\_\/]", "", regex=True)
                .str.replace(r"ì $", "", regex=True)
            )

            df_exact = df[
                (df["norm_name"].str.len() == mask_len)
                & (df["norm_name"].str.startswith(prefix_raw, na=False))
            ]
            df_relaxed = df[df["norm_name"].str.startswith(prefix_raw, na=False)]

            if not df_exact.empty:
                hit = df_exact
                priority = "ì •í™•ë§¤ì¹­"
            elif not df_relaxed.empty:
                hit = df_relaxed
                priority = "í™•ì¥ë§¤ì¹­"
            else:
                return {
                    "found": False,
                    "message": f"ë§ˆìŠ¤í‚¹ '{q}'ë¡œ ì¼ì¹˜/ìœ ì‚¬í•œ ê°€ë§¹ì ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "count": 0,
                    "merchants": [],
                    "search_type": "name",
                }

            hit = (
                hit.sort_values("ê¸°ì¤€ë…„ì›”", ascending=False)
                .drop_duplicates(subset=["ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸"], keep="first")
            )
            merchants = [
                {k: _to_py(v) for k, v in row.items()}
                for row in hit[
                    ["ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸", "ê°€ë§¹ì ëª…", "ê°€ë§¹ì _ì£¼ì†Œ", "ì—…ì¢…", "ìƒê¶Œ_ì§€ë¦¬"]
                ].to_dict("records")
            ]
            print(
                f"[DEBUG] (CSV) {priority}: {len(merchants)}ê±´ / prefix='{prefix_raw}', len={mask_len}"
            )
            return {
                "found": True,
                "message": f"ë§ˆìŠ¤í‚¹ '{q}' {priority} {len(merchants)}ê°œ",
                "count": len(merchants),
                "merchants": merchants,
                "search_type": "name",
            }

    # C) ì¼ë°˜ LIKE
    mask = df["ê°€ë§¹ì ëª…"].str.contains(q, case=False, na=False)
    hit = df[mask].copy()
    if hit.empty:
        return {
            "found": False,
            "message": f"'{q}'ì™€ ì¼ì¹˜í•˜ëŠ” ê°€ë§¹ì ì´ ì—†ìŠµë‹ˆë‹¤.",
            "count": 0,
            "merchants": [],
            "search_type": "name",
        }

    hit = (
        hit.sort_values("ê¸°ì¤€ë…„ì›”", ascending=False)
        .drop_duplicates(subset=["ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸"], keep="first")
    )
    merchants = [
        {k: _to_py(v) for k, v in row.items()}
        for row in hit.head(50)[
            ["ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸", "ê°€ë§¹ì ëª…", "ê°€ë§¹ì _ì£¼ì†Œ", "ì—…ì¢…", "ìƒê¶Œ_ì§€ë¦¬"]
        ].to_dict("records")
    ]
    return {
        "found": True,
        "message": f"'{q}' ê²€ìƒ‰ ê²°ê³¼ {len(merchants)}ê°œ",
        "count": len(merchants),
        "merchants": merchants,
        "search_type": "name",
    }



# ê°€ë§¹ì  ë°ì´í„° ì¡°íšŒ
def load_store_data(store_id: str, latest_only: bool = True) -> Dict[str, Any]:
    """
    store_id ê¸°ì¤€ìœ¼ë¡œ ê°€ë§¹ì  ë°ì´í„° ì¡°íšŒ
    
    Args:
        store_id: ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸
        latest_only: True â†’ ìµœì‹  1ê±´(dict), False â†’ ì „ì²´ ì´ë ¥(list[dict])
    
    Returns:
        {"success": bool, "data": dict or list, "error": str or None}
    """
    sid = str(store_id)
    
    # DuckDB ì‚¬ìš©
    if USE_DUCKDB:
        con = _get_db_connection()
        
        if latest_only:
            query = """
            SELECT * FROM franchise
            WHERE ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸ = ?
            ORDER BY ê¸°ì¤€ë…„ì›” DESC
            LIMIT 1
            """
            result = con.execute(query, [sid]).fetchdf()
            
            if result.empty:
                return {"success": False, "data": None, "error": f"ê°€ë§¹ì  {sid} ì—†ìŒ"}
            
            return {
                "success": True,
                "data": result.iloc[0].to_dict(),
                "error": None
            }
        else:
            query = """
            SELECT * FROM franchise
            WHERE ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸ = ?
            ORDER BY ê¸°ì¤€ë…„ì›” ASC
            """
            result = con.execute(query, [sid]).fetchdf()
            
            if result.empty:
                return {"success": False, "data": None, "error": f"ê°€ë§¹ì  {sid} ì—†ìŒ"}
            
            return {
                "success": True,
                "data": result.to_dict("records"),
                "error": None
            }
    
    # CSV ì‚¬ìš© (ë ˆê±°ì‹œ)
    else:
        df = _load_franchise_df()
        
        if "ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸" not in df.columns:
            return {"success": False, "data": None, "error": "ì»¬ëŸ¼ 'ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸' ì—†ìŒ"}
        
        store_df = df[df["ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸"] == sid].copy()
        if store_df.empty:
            return {"success": False, "data": None, "error": f"store_id {sid} not found"}
        
        if "ê¸°ì¤€ë…„ì›”" in store_df.columns:
            store_df = store_df.sort_values("ê¸°ì¤€ë…„ì›”")
        
        if latest_only:
            return {
                "success": True,
                "data": _to_serializable_row(store_df.iloc[-1]),
                "error": None
            }
        else:
            return {
                "success": True,
                "data": _to_serializable_records(store_df),
                "error": None
            }


# ìƒê¶Œ ë°ì´í„° ì¡°íšŒ
def load_bizarea_data(store_row: Dict[str, Any], all_matches: bool = False) -> Dict[str, Any]:
    """ìƒê¶Œ ë°ì´í„° ì¡°íšŒ
    - DuckDB: ì¡°ê±´ ì¼ì¹˜ í–‰ ì „ë¶€(or 1ê±´) ë°˜í™˜. (ìƒê¶Œ_ì½”ë“œ ì»¬ëŸ¼ ì˜ì¡´ ì œê±°)
    - CSV  : ì •í™• ë§¤ì¹­ ì‹¤íŒ¨ í™•ë¥  0 â†’ í•­ìƒ ë‹¨ê±´ ë°˜í™˜ (all_matches ë¬´ì‹œ)
    """
    required = ["ê¸°ì¤€ë…„ì›”", "ì—…ì¢…", "ìƒê¶Œ_ì§€ë¦¬"]
    missing = [k for k in required if k not in store_row or not store_row.get(k)]
    if missing:
        return {"success": False, "data": None, "error": f"í•„ìˆ˜ í‚¤ ëˆ„ë½: {', '.join(missing)}"}

    yyyymm = str(store_row["ê¸°ì¤€ë…„ì›”"])
    area_geo = str(store_row["ìƒê¶Œ_ì§€ë¦¬"])
    industry = str(store_row["ì—…ì¢…"])

    if USE_DUCKDB:
        con = _get_db_connection()
        if all_matches:
            # ì „ì²´ ë§¤ì¹­ í–‰ ë°˜í™˜ (ì •ë ¬/ìƒê¶Œ_ì½”ë“œ ì˜ì¡´ ì œê±°)
            query = """
            SELECT *
            FROM biz_area
            WHERE ê¸°ì¤€ë…„ì›” = ? AND ìƒê¶Œ_ì§€ë¦¬ = ? AND ì—…ì¢… = ?
            """
            params = [yyyymm, area_geo, industry]
            df = con.execute(query, params).fetchdf()
            if df.empty:
                return {"success": False, "data": None, "error": "ìƒê¶Œ ë°ì´í„° ì—†ìŒ"}
            return {"success": True, "data": df.to_dict("records"), "error": None}
        else:
            # ë‹¨ê±´ë§Œ í•„ìš” â†’ LIMIT 1 (ì¤‘ë³µ ì œê±°/ì •ë ¬ ë¶ˆí•„ìš”)
            query = """
            SELECT *
            FROM biz_area
            WHERE ê¸°ì¤€ë…„ì›” = ? AND ìƒê¶Œ_ì§€ë¦¬ = ? AND ì—…ì¢… = ?
            LIMIT 1
            """
            params = [yyyymm, area_geo, industry]
            df = con.execute(query, params).fetchdf()
            if df.empty:
                return {"success": False, "data": None, "error": "ìƒê¶Œ ë°ì´í„° ì—†ìŒ"}
            return {"success": True, "data": df.iloc[0].to_dict(), "error": None}

    # CSV ë¶„ê¸°: ì •í™• ë§¤ì¹­ ì‹¤íŒ¨ í™•ë¥  0 â†’ í•­ìƒ ë‹¨ê±´ ë°˜í™˜
    # all_matches ì¸ìëŠ” ë¬´ì‹œ(í•˜ìœ„í˜¸í™˜ ìœ„í•´ ìœ ì§€)
    df_biz = _load_bizarea_df()
    hit = df_biz[
        (df_biz["ê¸°ì¤€ë…„ì›”"] == yyyymm) &
        (df_biz["ìƒê¶Œ_ì§€ë¦¬"] == area_geo) &
        (df_biz["ì—…ì¢…"] == industry)
    ].copy()

    if hit.empty:
        return {"success": False, "data": None, "error": "bizarea not found"}

    # ì •ë ¬ ë¶ˆí•„ìš”, ìƒê¶Œ_ì½”ë“œë„ ì—†ìŒ â†’ ì²« í–‰ë§Œ ì§ ë°˜í™˜
    return {"success": True, "data": _to_serializable_row(hit.iloc[0]), "error": None}


def find_cooperation_candidates(area_geo: str, industry: str, main_customers: List[str], limit: int = 10) -> Dict[str, Any]:
    """
    í˜‘ì—… í›„ë³´ ê°€ë§¹ì  ì¡°íšŒ
    - ê°™ì€ ìƒê¶Œ ë‚´ì—ì„œ ì—…ì¢…ì´ ë‹¤ë¥´ì§€ë§Œ ì£¼ìš” ê³ ê°ì¸µì´ ê²¹ì¹˜ëŠ” ê°€ë§¹ì  í›„ë³´ë¥¼ íƒìƒ‰
    
    Args:
        area_geo (str): ìƒê¶Œ_ì§€ë¦¬
        industry (str): í˜„ì¬ ì—…ì¢…
        main_customers (List[str]): í•µì‹¬ ê³ ê°ì¸µ ë¦¬ìŠ¤íŠ¸
        limit (int): ê²°ê³¼ ì œí•œ ìˆ˜ (ê¸°ë³¸ 10)

    Returns:
        {"success": bool, "count": int, "candidates": List[dict], "error": str or None}
    """
    print(f"[DEBUG] find_cooperation_candidates called with area_geo={area_geo}, industry={industry}, main_customers={main_customers}, limit={limit}")
    if not area_geo or not industry or not main_customers:
        return {
            "success": False,
            "count": 0,
            "candidates": [],
            "error": "í•„ìˆ˜ ì¸ì ëˆ„ë½ (area_geo, industry, main_customers)"
        }

    con = _get_db_connection()
    mc_tuple = ", ".join([f"'{x}'" for x in main_customers])
    query = f"""
        SELECT DISTINCT
            ê°€ë§¹ì _êµ¬ë¶„ë²ˆí˜¸, ê°€ë§¹ì ëª…, ì—…ì¢…,
            í•µì‹¬ê³ ê°_1ìˆœìœ„, í•µì‹¬ê³ ê°_2ìˆœìœ„, í•µì‹¬ê³ ê°_3ìˆœìœ„,
            ê±°ì£¼ê³ ê°_ë¹„ì¤‘, ì§ì¥ê³ ê°_ë¹„ì¤‘, ìœ ë™ì¸êµ¬ê³ ê°_ë¹„ì¤‘
        FROM franchise
        WHERE (ìƒê¶Œ = '{area_geo}' OR ìƒê¶Œ_ì§€ë¦¬ = '{area_geo}')
        AND ì—…ì¢… != '{industry}'
        AND (
                í•µì‹¬ê³ ê°_1ìˆœìœ„ IN ({mc_tuple})
            OR í•µì‹¬ê³ ê°_2ìˆœìœ„ IN ({mc_tuple})
            OR í•µì‹¬ê³ ê°_3ìˆœìœ„ IN ({mc_tuple})
        )
        ORDER BY ê¸°ì¤€ë…„ì›” DESC
        LIMIT {limit}
    """
    print("[DEBUG] SQL Query:")
    print(query)
    try:
        df = con.execute(query).fetchdf()
        if df.empty:
            return {"success": True, "count": 0, "candidates": [], "error": None}
        
        return {"success": True, "count": len(df), "candidates": df.to_dict("records"), "error": None}
    except Exception as e:

        return {"success": False, "count": 0, "candidates": [], "error": str(e)}